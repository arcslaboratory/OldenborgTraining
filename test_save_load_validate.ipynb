{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c30056e-ed09-43c5-9eb9-27485fb2becf",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "- [fastai/fastai/learner.py at master Â· fastai/fastai](https://github.com/fastai/fastai/blob/master/fastai/learner.py)\n",
    "- [fastai - Callbacks](https://docs.fast.ai/callback.core.html#trainevalcallback)\n",
    "- [fastai - Learner, Metrics, Callbacks](https://docs.fast.ai/learner.html#learner)\n",
    "\n",
    "TODO:\n",
    "\n",
    "- try with `opt=None` for save/load (pass to both save and load)\n",
    "- with and without: `Learner.model.eval()`\n",
    "- with and without: `Learner.model.cuda()` or `.cpu()`\n",
    "\n",
    "Order of `.predict`\n",
    "\n",
    "1. creates `dl` using `self.dls.test_dl`\n",
    "2. calls `self.get_preds`\n",
    "3. calls `self._do_epoch_validate`\n",
    "4. sets `self.dl` and calls `self.all_batches` with `torch.no_grad()`\n",
    "5. calls `self.one_batch` with data from `self.dl`\n",
    "6. calls `self._do_one_batch`\n",
    "7. calls `self.model(self.xb)`\n",
    "\n",
    "Call stack for training\n",
    "\n",
    "1. call `learn.fit`\n",
    "2. `self.fit`\n",
    "3. calls `self._do_fit`\n",
    "4. calls `self._do_epoch` for each epoch\n",
    "5. `self._do_epoch_train` also sets `self.dl` and calls `self.all_batches` (also calls `self._do_epoch_validate`)\n",
    "6. same sequence as shown in `.predict`\n",
    "\n",
    "`get_preds` always results in `torch.no_grad()`\n",
    "\n",
    "To consider:\n",
    "\n",
    "- `Learner.validate`\n",
    "- `Learner.one_batch` (set in train mode with `TrainEvalCallback.training = ...`\n",
    "- `Learner.all_batches`\n",
    "- manually handling transforms (probably never worth the effort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784800b-b59b-4690-9573-56e2bf539d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from math import radians\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from torch import cuda\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "cuda.set_device(2)\n",
    "print(\"Running on GPU:\", cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed834173-9f70-4a90-b1fc-31cbe4dab192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy_using_predict(learn, image_filenames):\n",
    "    num_images = len(image_filenames)\n",
    "    num_correct = 0\n",
    "\n",
    "    for image_filename in tqdm(image_filenames):\n",
    "        with learn.no_bar(), learn.no_logging():\n",
    "            prediction, _, _ = learn.predict(image_filename)\n",
    "        target = y_from_filename(rotation_threshold, image_filename)\n",
    "        num_correct += int(prediction == target)\n",
    "\n",
    "    accuracy = num_correct / num_images\n",
    "    print(f\"Accuracy using `.predict`: {accuracy:.2%}\")\n",
    "\n",
    "\n",
    "def print_accuracy_using_get_preds(learn, image_filenames):\n",
    "    dl_test = learn.dls.test_dl(image_filenames, with_labels=True)\n",
    "    # with learn.no_bar(), learn.no_logging():\n",
    "    _, predictions, targets = learn.get_preds(dl=dl_test, with_decoded=True)\n",
    "    accuracy = (predictions == targets).float().mean()\n",
    "    print(f\"Accuracy using `.dls.test_dl` and `.get_preds`: {accuracy:.2%}\")\n",
    "\n",
    "\n",
    "def print_accuracy_using_model(learn, image_filenames):\n",
    "    num_images = len(image_filenames)\n",
    "    num_correct = 0\n",
    "    \n",
    "    dl = learn.dls.test_dl(image_filenames, with_labels=True)\n",
    "    learn.model.eval()\n",
    "    learn.model.to(\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        for image_batch, label_batch in tqdm(dl):\n",
    "            image_batch = image_batch.to(\"cpu\")\n",
    "            label_batch = label_batch.to(\"cpu\")\n",
    "            output_batch = learn.model(image_batch)\n",
    "            num_correct += (F.softmax(output_batch, dim=learn.loss_func.axis).argmax(dim=-1) == label_batch).sum()\n",
    "\n",
    "    accuracy = (num_correct / num_images).item()\n",
    "    print(f\"Accuracy using `.model`: {accuracy:.2%}\")\n",
    "\n",
    "\n",
    "def print_accuracy(learn, image_filenames):\n",
    "    print_accuracy_using_predict(learn, image_filenames)\n",
    "    print_accuracy_using_get_preds(learn, image_filenames)\n",
    "    print_accuracy_using_model(learn, image_filenames)\n",
    "\n",
    "\n",
    "def y_from_filename(rotation_threshold, filename) -> str:\n",
    "    \"\"\"Extracts the direction label from the filename of an image.\n",
    "\n",
    "    Example: \"path/to/file/001_000011_-1p50.png\" --> \"right\"\n",
    "    \"\"\"\n",
    "    filename_stem = Path(filename).stem\n",
    "    angle = float(filename_stem.split(\"_\")[2].replace(\"p\", \".\"))\n",
    "\n",
    "    if angle > rotation_threshold:\n",
    "        return \"left\"\n",
    "    elif angle < -rotation_threshold:\n",
    "        return \"right\"\n",
    "    else:\n",
    "        return \"forward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f582df8-ab78-473e-9f64-65a8a22d9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./data/\")\n",
    "\n",
    "image_filenames: list = get_image_files(data_path)\n",
    "assert len(image_filenames) > 0\n",
    "\n",
    "rotation_threshold = radians(5)\n",
    "\n",
    "label_func = partial(y_from_filename, rotation_threshold)\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    data_path,\n",
    "    image_filenames,\n",
    "    label_func,\n",
    "    valid_pct=0.2,\n",
    "    shuffle=True,\n",
    "    bs=64,\n",
    "    item_tfms=Resize(224),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c486a-463b-40fd-93c5-027022efff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fit_one_cycle(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756ff01-b43c-4dbe-b864-2ec2ee001492",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_save_model_function_filename = \"_by_save_model_function\"\n",
    "\n",
    "\n",
    "# Saves model state_dict [and optimizer state_dict] using torch.save\n",
    "save_model(by_save_model_function_filename, learn, learn.opt)\n",
    "\n",
    "# Loads model state_dict [and optimizer state_dict] using torch.load\n",
    "# and model.load_state_dict [and optimizer.load_state_dict]\n",
    "# NOTE: requires dls\n",
    "learn_by_save_model_function = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "load_model(by_save_model_function_filename, learn_by_save_model_function, learn.opt)\n",
    "\n",
    "print_accuracy(learn_by_save_model_function, image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063ed4a-c077-4857-b8bf-0b64ebe76d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_save_method_filename = \"_by_save_method\"\n",
    "\n",
    "learn.save(by_save_method_filename)\n",
    "\n",
    "# NOTE: requires dls (probably good to use training dls for built-in transforms)\n",
    "learn_by_save_method = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn_by_save_method.load(by_save_method_filename)\n",
    "\n",
    "print_accuracy(learn_by_save_method, image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d852e761-01e8-4ab9-94bd-3ccd2c52509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_export_method_filename = \"_by_export_method\"\n",
    "\n",
    "learn.export(by_export_method_filename)\n",
    "learn_by_export_method = load_learner(data_path/by_export_method_filename)\n",
    "\n",
    "print_accuracy(learn_by_export_method, image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ecbea-62fe-4868-a8ef-49d130e4ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_torch_save_function_filename = \"_by_torch_save_function\"\n",
    "\n",
    "torch.save(learn.model.state_dict(), by_torch_save_function_filename)\n",
    "\n",
    "# NOTE: requires dls (probably good to use training dls for built-in transforms)\n",
    "learn_by_torch_save_function = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn_by_torch_save_function.model.load_state_dict(torch.load(by_torch_save_function_filename))\n",
    "\n",
    "print_accuracy(learn_by_torch_save_function, image_filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
